{"cells":[{"cell_type":"code","execution_count":5,"id":"8d599232","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName(\"CS131-A4-Taxi\").getOrCreate()\n"]},{"cell_type":"code","execution_count":9,"id":"d4404740","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["root\n"," |-- vendorid: double (nullable = true)\n"," |-- tpep_pickup_datetime: timestamp (nullable = true)\n"," |-- tpep_dropoff_datetime: timestamp (nullable = true)\n"," |-- passenger_count: double (nullable = true)\n"," |-- trip_distance: double (nullable = true)\n"," |-- ratecodeid: double (nullable = true)\n"," |-- store_and_fwd_flag: string (nullable = true)\n"," |-- pulocationid: double (nullable = true)\n"," |-- dolocationid: double (nullable = true)\n"," |-- payment_type: double (nullable = true)\n"," |-- fare_amount: double (nullable = true)\n"," |-- extra: double (nullable = true)\n"," |-- mta_tax: double (nullable = true)\n"," |-- tip_amount: double (nullable = true)\n"," |-- tolls_amount: double (nullable = true)\n"," |-- improvement_surcharge: double (nullable = true)\n"," |-- total_amount: double (nullable = true)\n"," |-- congestion_surcharge: double (nullable = true)\n","\n","+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n","|vendorid|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|ratecodeid|store_and_fwd_flag|pulocationid|dolocationid|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n","+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n","|     1.0| 2019-01-01 00:46:40|  2019-01-01 00:53:20|            1.0|          1.5|       1.0|                 N|       151.0|       239.0|         1.0|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                NULL|\n","|     1.0| 2019-01-01 00:59:47|  2019-01-01 01:18:59|            1.0|          2.6|       1.0|                 N|       239.0|       246.0|         1.0|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        16.3|                NULL|\n","|     2.0| 2018-12-21 13:48:30|  2018-12-21 13:52:40|            3.0|          0.0|       1.0|                 N|       236.0|       236.0|         1.0|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.8|                NULL|\n","|     2.0| 2018-11-28 15:52:25|  2018-11-28 15:55:45|            5.0|          0.0|       1.0|                 N|       193.0|       193.0|         2.0|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        7.55|                NULL|\n","|     2.0| 2018-11-28 15:56:57|  2018-11-28 15:58:33|            5.0|          0.0|       2.0|                 N|       193.0|       193.0|         2.0|       52.0|  0.0|    0.5|       0.0|         0.0|                  0.3|       55.55|                NULL|\n","+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["file_path = \"gs://taxidatasaet/2019-01-h1.csv\"\n","\n","df = spark.read.csv(file_path, header=True, inferSchema=True)\n","df.printSchema()\n","df.show(5)\n"]},{"cell_type":"code","execution_count":10,"id":"3d4ac651","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+\n","|passenger_count|PULocationID|DOLocationID|total_amount|\n","+---------------+------------+------------+------------+\n","|            1.0|       151.0|       239.0|        9.95|\n","|            1.0|       239.0|       246.0|        16.3|\n","|            3.0|       236.0|       236.0|         5.8|\n","|            5.0|       193.0|       193.0|        7.55|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            5.0|       193.0|       193.0|       13.31|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            1.0|       163.0|       229.0|        9.05|\n","|            1.0|       229.0|         7.0|        18.5|\n","|            2.0|       141.0|       234.0|        13.0|\n","+---------------+------------+------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["selected_df = df.select(\"passenger_count\", \"PULocationID\", \"DOLocationID\", \"total_amount\")\n","selected_df.show(10)\n"]},{"cell_type":"code","execution_count":12,"id":"f40aa8bf","metadata":{},"outputs":[],"source":["trainDF, testDF = selected_df.randomSplit([0.8, 0.2], seed=42)"]},{"cell_type":"code","execution_count":13,"id":"84ff9700","metadata":{},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.regression import DecisionTreeRegressor\n","from pyspark.ml import Pipeline\n","\n","assembler = VectorAssembler(\n","    inputCols=[\"passenger_count\", \"PULocationID\", \"DOLocationID\"],\n","    outputCol=\"features\"\n",")\n","\n","# Decision Tree Regressor\n","dtr = DecisionTreeRegressor(\n","    featuresCol=\"features\",\n","    labelCol=\"total_amount\"\n",")\n","\n","dtr.setMaxBins(100)\n","\n","pipeline = Pipeline(stages=[assembler, dtr])\n"]},{"cell_type":"code","execution_count":14,"id":"e08b6e5a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["model = pipeline.fit(trainDF)\n"]},{"cell_type":"code","execution_count":15,"id":"4bfc9f70","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 18:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------------+\n","|passenger_count|PULocationID|DOLocationID|        prediction|\n","+---------------+------------+------------+------------------+\n","|            0.0|         4.0|         4.0| 24.03192497663894|\n","|            0.0|         4.0|        33.0|18.581726675586104|\n","|            0.0|         4.0|        68.0|18.581726675586104|\n","|            0.0|         4.0|        79.0|18.581726675586104|\n","|            0.0|         4.0|       125.0|18.581726675586104|\n","|            0.0|         4.0|       170.0|18.581726675586104|\n","|            0.0|         7.0|         7.0|18.891607300712764|\n","|            0.0|         7.0|         7.0|18.891607300712764|\n","|            0.0|         7.0|       112.0|18.581726675586104|\n","|            0.0|         7.0|       138.0|18.581726675586104|\n","+---------------+------------+------------+------------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["predictions = model.transform(testDF)\n","\n","predictions.select(\"passenger_count\", \"PULocationID\", \"DOLocationID\", \"prediction\").show(10)"]},{"cell_type":"code","execution_count":16,"id":"c1e6a3d8","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 19:===========================================>              (3 + 1) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["Root Mean Squared Error (RMSE): 60.27038711535193\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","\n","evaluator = RegressionEvaluator(\n","    labelCol=\"total_amount\",\n","    predictionCol=\"prediction\",\n","    metricName=\"rmse\"\n",")\n","\n","rmse = evaluator.evaluate(predictions)\n","print(f\"Root Mean Squared Error (RMSE): {rmse}\")"]},{"cell_type":"code","execution_count":null,"id":"bc718a4e","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}